{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ludwig.api import LudwigModel\n",
    "import logging\n",
    "import shutil\n",
    "import yaml\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean out prior results\n",
    "try:\n",
    "    shutil.rmtree('./results')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Python dictionary to hold model training parameters\n",
    "with open('./model_definition.yaml','r') as f:\n",
    "    model_definition = yaml.safe_load(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_features': [{'conv_layers': [{'filter_size': 3,\n",
      "                                      'num_filters': 32,\n",
      "                                      'pool_size': 2,\n",
      "                                      'pool_stride': 2},\n",
      "                                     {'dropout': True,\n",
      "                                      'filter_size': 3,\n",
      "                                      'num_filters': 64,\n",
      "                                      'pool_size': 2,\n",
      "                                      'pool_stride': 2}],\n",
      "                     'encoder': 'stacked_cnn',\n",
      "                     'fc_layers': [{'dropout': True, 'fc_size': 128}],\n",
      "                     'name': 'image_path',\n",
      "                     'preprocessing': {'num_processes': 4},\n",
      "                     'type': 'image'}],\n",
      " 'output_features': [{'name': 'label', 'type': 'category'}],\n",
      " 'training': {'dropout_rate': 0.4, 'epochs': 10}}\n"
     ]
    }
   ],
   "source": [
    "pprint(model_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Ludwig model object that drive model training\n",
    "model = LudwigModel(model_definition,\n",
    "                    logging_level=logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: simple_image_experiment\n",
      "Model name: single_model\n",
      "Output path: results/simple_image_experiment_single_model_0\n",
      "\n",
      "\n",
      "ludwig_version: '0.2.1'\n",
      "command: ('/opt/anaconda/envs/wmlce/lib/python3.7/site-packages/ipykernel_launcher.py '\n",
      " '-f '\n",
      " '/root/.local/share/jupyter/runtime/kernel-ac8de605-c4f8-4382-b3ac-175ac6e28915.json')\n",
      "commit_hash: '3cbd9aa5fd1d'\n",
      "random_seed: 42\n",
      "input_data_train: './data/mnist_dataset_training.csv'\n",
      "input_data_test: './data/mnist_dataset_testing.csv'\n",
      "model_definition: {   'combiner': {'type': 'concat'},\n",
      "    'input_features': [   {   'conv_layers': [   {   'filter_size': 3,\n",
      "                                                     'num_filters': 32,\n",
      "                                                     'pool_size': 2,\n",
      "                                                     'pool_stride': 2},\n",
      "                                                 {   'dropout': True,\n",
      "                                                     'filter_size': 3,\n",
      "                                                     'num_filters': 64,\n",
      "                                                     'pool_size': 2,\n",
      "                                                     'pool_stride': 2}],\n",
      "                              'encoder': 'stacked_cnn',\n",
      "                              'fc_layers': [{'dropout': True, 'fc_size': 128}],\n",
      "                              'name': 'image_path',\n",
      "                              'preprocessing': {'num_processes': 4},\n",
      "                              'tied_weights': None,\n",
      "                              'type': 'image'}],\n",
      "    'output_features': [   {   'dependencies': [],\n",
      "                               'loss': {   'class_similarities_temperature': 0,\n",
      "                                           'class_weights': 1,\n",
      "                                           'confidence_penalty': 0,\n",
      "                                           'distortion': 1,\n",
      "                                           'labels_smoothing': 0,\n",
      "                                           'negative_samples': 0,\n",
      "                                           'robust_lambda': 0,\n",
      "                                           'sampler': None,\n",
      "                                           'type': 'softmax_cross_entropy',\n",
      "                                           'unique': False,\n",
      "                                           'weight': 1},\n",
      "                               'name': 'label',\n",
      "                               'reduce_dependencies': 'sum',\n",
      "                               'reduce_input': 'sum',\n",
      "                               'top_k': 3,\n",
      "                               'type': 'category'}],\n",
      "    'preprocessing': {   'audio': {   'audio_feature': {'type': 'raw'},\n",
      "                                      'audio_file_length_limit_in_s': 7.5,\n",
      "                                      'in_memory': True,\n",
      "                                      'missing_value_strategy': 'backfill',\n",
      "                                      'norm': None,\n",
      "                                      'padding_value': 0},\n",
      "                         'bag': {   'fill_value': '',\n",
      "                                    'lowercase': False,\n",
      "                                    'missing_value_strategy': 'fill_with_const',\n",
      "                                    'most_common': 10000,\n",
      "                                    'tokenizer': 'space'},\n",
      "                         'binary': {   'fill_value': 0,\n",
      "                                       'missing_value_strategy': 'fill_with_const'},\n",
      "                         'category': {   'fill_value': '<UNK>',\n",
      "                                         'lowercase': False,\n",
      "                                         'missing_value_strategy': 'fill_with_const',\n",
      "                                         'most_common': 10000},\n",
      "                         'date': {   'datetime_format': None,\n",
      "                                     'fill_value': '',\n",
      "                                     'missing_value_strategy': 'fill_with_const'},\n",
      "                         'force_split': False,\n",
      "                         'h3': {   'fill_value': 576495936675512319,\n",
      "                                   'missing_value_strategy': 'fill_with_const'},\n",
      "                         'image': {   'in_memory': True,\n",
      "                                      'missing_value_strategy': 'backfill',\n",
      "                                      'num_processes': 1,\n",
      "                                      'resize_method': 'interpolate',\n",
      "                                      'scaling': 'pixel_normalization'},\n",
      "                         'numerical': {   'fill_value': 0,\n",
      "                                          'missing_value_strategy': 'fill_with_const',\n",
      "                                          'normalization': None},\n",
      "                         'sequence': {   'fill_value': '',\n",
      "                                         'lowercase': False,\n",
      "                                         'missing_value_strategy': 'fill_with_const',\n",
      "                                         'most_common': 20000,\n",
      "                                         'padding': 'right',\n",
      "                                         'padding_symbol': '<PAD>',\n",
      "                                         'sequence_length_limit': 256,\n",
      "                                         'tokenizer': 'space',\n",
      "                                         'unknown_symbol': '<UNK>',\n",
      "                                         'vocab_file': None},\n",
      "                         'set': {   'fill_value': '',\n",
      "                                    'lowercase': False,\n",
      "                                    'missing_value_strategy': 'fill_with_const',\n",
      "                                    'most_common': 10000,\n",
      "                                    'tokenizer': 'space'},\n",
      "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
      "                         'stratify': None,\n",
      "                         'text': {   'char_most_common': 70,\n",
      "                                     'char_sequence_length_limit': 1024,\n",
      "                                     'char_tokenizer': 'characters',\n",
      "                                     'char_vocab_file': None,\n",
      "                                     'fill_value': '',\n",
      "                                     'lowercase': True,\n",
      "                                     'missing_value_strategy': 'fill_with_const',\n",
      "                                     'padding': 'right',\n",
      "                                     'padding_symbol': '<PAD>',\n",
      "                                     'unknown_symbol': '<UNK>',\n",
      "                                     'word_most_common': 20000,\n",
      "                                     'word_sequence_length_limit': 256,\n",
      "                                     'word_tokenizer': 'space_punct',\n",
      "                                     'word_vocab_file': None},\n",
      "                         'timeseries': {   'fill_value': '',\n",
      "                                           'missing_value_strategy': 'fill_with_const',\n",
      "                                           'padding': 'right',\n",
      "                                           'padding_value': 0,\n",
      "                                           'timeseries_length_limit': 256,\n",
      "                                           'tokenizer': 'space'},\n",
      "                         'vector': {   'fill_value': '',\n",
      "                                       'missing_value_strategy': 'fill_with_const'}},\n",
      "    'training': {   'batch_size': 128,\n",
      "                    'bucketing_field': None,\n",
      "                    'decay': False,\n",
      "                    'decay_rate': 0.96,\n",
      "                    'decay_steps': 10000,\n",
      "                    'dropout_rate': 0.4,\n",
      "                    'early_stop': 5,\n",
      "                    'epochs': 10,\n",
      "                    'eval_batch_size': 0,\n",
      "                    'gradient_clipping': None,\n",
      "                    'increase_batch_size_on_plateau': 0,\n",
      "                    'increase_batch_size_on_plateau_max': 512,\n",
      "                    'increase_batch_size_on_plateau_patience': 5,\n",
      "                    'increase_batch_size_on_plateau_rate': 2,\n",
      "                    'learning_rate': 0.001,\n",
      "                    'learning_rate_warmup_epochs': 1,\n",
      "                    'optimizer': {   'beta1': 0.9,\n",
      "                                     'beta2': 0.999,\n",
      "                                     'epsilon': 1e-08,\n",
      "                                     'type': 'adam'},\n",
      "                    'reduce_learning_rate_on_plateau': 0,\n",
      "                    'reduce_learning_rate_on_plateau_patience': 5,\n",
      "                    'reduce_learning_rate_on_plateau_rate': 0.5,\n",
      "                    'regularization_lambda': 0,\n",
      "                    'regularizer': 'l2',\n",
      "                    'staircase': False,\n",
      "                    'validation_field': 'combined',\n",
      "                    'validation_measure': 'loss'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Using training raw csv, no hdf5 and json file with the same name have been found\n",
      "Building dataset (it may take a while)\n",
      "Loading training csv...\n",
      "done\n",
      "Loading validation csv..\n",
      "done\n",
      "Loading test csv..\n",
      "done\n",
      "Concatenating csvs..\n",
      "done\n",
      "Using 4 processes for preprocessing images\n",
      "Writing dataset\n",
      "Writing train set metadata with vocabulary\n",
      "Training set: 60000\n",
      "Test set: 10000\n",
      "WARNING:tensorflow:From /opt/anaconda/envs/wmlce/lib/python3.7/site-packages/ludwig-0.2.1-py3.7.egg/ludwig/models/modules/convolutional_modules.py:74: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /opt/anaconda/envs/wmlce/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:271: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /opt/anaconda/envs/wmlce/lib/python3.7/site-packages/ludwig-0.2.1-py3.7.egg/ludwig/models/modules/convolutional_modules.py:585: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "\n",
      "╒══════════╕\n",
      "│ TRAINING │\n",
      "╘══════════╛\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda/envs/wmlce/lib/python3.7/site-packages/ludwig-0.2.1-py3.7.egg/ludwig/utils/tf_utils.py:78: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "\n",
      "Epoch  1\n",
      "Training: 100%|██████████| 469/469 [00:04<00:00, 108.84it/s]\n",
      "Evaluation train: 100%|██████████| 469/469 [00:00<00:00, 473.68it/s]\n",
      "Evaluation test : 100%|██████████| 79/79 [00:00<00:00, 461.24it/s]\n",
      "Took 5.5013s\n",
      "╒═════════╤════════╤════════════╤═════════════╕\n",
      "│ label   │   loss │   accuracy │   hits_at_k │\n",
      "╞═════════╪════════╪════════════╪═════════════╡\n",
      "│ train   │ 2.0360 │     0.2597 │      0.3886 │\n",
      "├─────────┼────────┼────────────┼─────────────┤\n",
      "│ test    │ 2.0273 │     0.2620 │      0.3898 │\n",
      "╘═════════╧════════╧════════════╧═════════════╛\n",
      "\n",
      "\n",
      "Epoch  2\n",
      "Training: 100%|██████████| 469/469 [00:01<00:00, 236.28it/s]\n",
      "Evaluation train: 100%|██████████| 469/469 [00:00<00:00, 498.68it/s]\n",
      "Evaluation test : 100%|██████████| 79/79 [00:00<00:00, 516.37it/s]\n",
      "Took 3.8511s\n",
      "╒═════════╤════════╤════════════╤═════════════╕\n",
      "│ label   │   loss │   accuracy │   hits_at_k │\n",
      "╞═════════╪════════╪════════════╪═════════════╡\n",
      "│ train   │ 1.5850 │     0.4335 │      0.6633 │\n",
      "├─────────┼────────┼────────────┼─────────────┤\n",
      "│ test    │ 1.5769 │     0.4324 │      0.6711 │\n",
      "╘═════════╧════════╧════════════╧═════════════╛\n",
      "\n",
      "\n",
      "Epoch  3\n",
      "Training: 100%|██████████| 469/469 [00:01<00:00, 245.25it/s]\n",
      "Evaluation train: 100%|██████████| 469/469 [00:00<00:00, 499.66it/s]\n",
      "Evaluation test : 100%|██████████| 79/79 [00:00<00:00, 506.46it/s]\n",
      "Took 3.1261s\n",
      "╒═════════╤════════╤════════════╤═════════════╕\n",
      "│ label   │   loss │   accuracy │   hits_at_k │\n",
      "╞═════════╪════════╪════════════╪═════════════╡\n",
      "│ train   │ 1.3199 │     0.5459 │      0.7623 │\n",
      "├─────────┼────────┼────────────┼─────────────┤\n",
      "│ test    │ 1.3134 │     0.5488 │      0.7682 │\n",
      "╘═════════╧════════╧════════════╧═════════════╛\n",
      "\n",
      "\n",
      "Epoch  4\n",
      "Training: 100%|██████████| 469/469 [00:01<00:00, 243.61it/s]\n",
      "Evaluation train: 100%|██████████| 469/469 [00:00<00:00, 509.38it/s]\n",
      "Evaluation test : 100%|██████████| 79/79 [00:00<00:00, 515.98it/s]\n",
      "Took 3.1737s\n",
      "╒═════════╤════════╤════════════╤═════════════╕\n",
      "│ label   │   loss │   accuracy │   hits_at_k │\n",
      "╞═════════╪════════╪════════════╪═════════════╡\n",
      "│ train   │ 1.2965 │     0.5286 │      0.7630 │\n",
      "├─────────┼────────┼────────────┼─────────────┤\n",
      "│ test    │ 1.2876 │     0.5347 │      0.7672 │\n",
      "╘═════════╧════════╧════════════╧═════════════╛\n",
      "\n",
      "\n",
      "Epoch  5\n",
      "Training: 100%|██████████| 469/469 [00:01<00:00, 241.71it/s]\n",
      "Evaluation train: 100%|██████████| 469/469 [00:00<00:00, 497.19it/s]\n",
      "Evaluation test : 100%|██████████| 79/79 [00:00<00:00, 509.29it/s]\n",
      "Took 3.4446s\n",
      "╒═════════╤════════╤════════════╤═════════════╕\n",
      "│ label   │   loss │   accuracy │   hits_at_k │\n",
      "╞═════════╪════════╪════════════╪═════════════╡\n",
      "│ train   │ 1.1160 │     0.6142 │      0.8360 │\n",
      "├─────────┼────────┼────────────┼─────────────┤\n",
      "│ test    │ 1.1242 │     0.6170 │      0.8395 │\n",
      "╘═════════╧════════╧════════════╧═════════════╛\n",
      "\n",
      "\n",
      "Epoch  6\n",
      "Training: 100%|██████████| 469/469 [00:01<00:00, 237.84it/s]\n",
      "Evaluation train: 100%|██████████| 469/469 [00:00<00:00, 508.67it/s]\n",
      "Evaluation test : 100%|██████████| 79/79 [00:00<00:00, 514.41it/s]\n",
      "Took 3.5476s\n",
      "╒═════════╤════════╤════════════╤═════════════╕\n",
      "│ label   │   loss │   accuracy │   hits_at_k │\n",
      "╞═════════╪════════╪════════════╪═════════════╡\n",
      "│ train   │ 1.0443 │     0.6274 │      0.8498 │\n",
      "├─────────┼────────┼────────────┼─────────────┤\n",
      "│ test    │ 1.0446 │     0.6262 │      0.8528 │\n",
      "╘═════════╧════════╧════════════╧═════════════╛\n",
      "\n",
      "\n",
      "Epoch  7\n",
      "Training: 100%|██████████| 469/469 [00:01<00:00, 237.99it/s]\n",
      "Evaluation train: 100%|██████████| 469/469 [00:00<00:00, 503.60it/s]\n",
      "Evaluation test : 100%|██████████| 79/79 [00:00<00:00, 506.61it/s]\n",
      "Took 3.6478s\n",
      "╒═════════╤════════╤════════════╤═════════════╕\n",
      "│ label   │   loss │   accuracy │   hits_at_k │\n",
      "╞═════════╪════════╪════════════╪═════════════╡\n",
      "│ train   │ 1.0295 │     0.6316 │      0.8477 │\n",
      "├─────────┼────────┼────────────┼─────────────┤\n",
      "│ test    │ 1.0313 │     0.6316 │      0.8507 │\n",
      "╘═════════╧════════╧════════════╧═════════════╛\n",
      "\n",
      "\n",
      "Epoch  8\n",
      "Training: 100%|██████████| 469/469 [00:01<00:00, 243.99it/s]\n",
      "Evaluation train: 100%|██████████| 469/469 [00:00<00:00, 512.96it/s]\n",
      "Evaluation test : 100%|██████████| 79/79 [00:00<00:00, 508.03it/s]\n",
      "Took 2.9990s\n",
      "╒═════════╤════════╤════════════╤═════════════╕\n",
      "│ label   │   loss │   accuracy │   hits_at_k │\n",
      "╞═════════╪════════╪════════════╪═════════════╡\n",
      "│ train   │ 0.9525 │     0.6543 │      0.8696 │\n",
      "├─────────┼────────┼────────────┼─────────────┤\n",
      "│ test    │ 0.9472 │     0.6544 │      0.8716 │\n",
      "╘═════════╧════════╧════════════╧═════════════╛\n",
      "\n",
      "\n",
      "Epoch  9\n",
      "Training: 100%|██████████| 469/469 [00:01<00:00, 240.98it/s]\n",
      "Evaluation train: 100%|██████████| 469/469 [00:00<00:00, 500.14it/s]\n",
      "Evaluation test : 100%|██████████| 79/79 [00:00<00:00, 507.23it/s]\n",
      "Took 3.4553s\n",
      "╒═════════╤════════╤════════════╤═════════════╕\n",
      "│ label   │   loss │   accuracy │   hits_at_k │\n",
      "╞═════════╪════════╪════════════╪═════════════╡\n",
      "│ train   │ 0.9287 │     0.6681 │      0.8811 │\n",
      "├─────────┼────────┼────────────┼─────────────┤\n",
      "│ test    │ 0.9339 │     0.6672 │      0.8822 │\n",
      "╘═════════╧════════╧════════════╧═════════════╛\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Training: 100%|██████████| 469/469 [00:01<00:00, 238.48it/s]\n",
      "Evaluation train: 100%|██████████| 469/469 [00:00<00:00, 505.41it/s]\n",
      "Evaluation test : 100%|██████████| 79/79 [00:00<00:00, 517.76it/s]\n",
      "Took 3.5452s\n",
      "╒═════════╤════════╤════════════╤═════════════╕\n",
      "│ label   │   loss │   accuracy │   hits_at_k │\n",
      "╞═════════╪════════╪════════════╪═════════════╡\n",
      "│ train   │ 0.9007 │     0.6650 │      0.8764 │\n",
      "├─────────┼────────┼────────────┼─────────────┤\n",
      "│ test    │ 0.8917 │     0.6663 │      0.8801 │\n",
      "╘═════════╧════════╧════════════╧═════════════╛\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initiate model training \n",
    "train_stats = model.train(data_train_csv='./data/mnist_dataset_training.csv',\n",
    "                          data_test_csv='./data/mnist_dataset_testing.csv',\n",
    "                         experiment_name='simple_image_experiment',\n",
    "                         model_name='single_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wmlce",
   "language": "python",
   "name": "wmlce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
